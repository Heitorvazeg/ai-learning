# ü§ñ Redes Neurais (Neural Networks)

Redes neurais s√£o **modelos de aprendizado de m√°quina** inspirados no **c√©rebro humano**,
 compostos por **neur√¥nios artificiais** que aprendem a reconhecer padr√µes a partir de dados.

---

## üß† Estrutura B√°sica

- **Camada de entrada (Input Layer)**  
  Recebe os dados brutos de entrada.

- **Camadas ocultas (Hidden Layers)**  
  Realizam c√°lculos com **pesos** e aplicam **fun√ß√µes de ativa√ß√£o** para extrair padr√µes.

- **Camada de sa√≠da (Output Layer)**  
  Fornece a **resposta final** do modelo.

---

## üîπ Neur√¥nio

- Cada **neur√¥nio** recebe um valor entre `0` e `1`, chamado de **Activation**.
- A ativa√ß√£o representa **o qu√£o "ativo" (positivo)** aquele neur√¥nio est√° em rela√ß√£o ao padr√£o que ele reconhece.

### Elementos-chave:
- **Peso (Weight):** Intensidade da conex√£o entre neur√¥nios.
- **Bias (Vi√©s):** Valor adicional que define o qu√£o alto o sinal precisa ser para "fazer sentido".
- **Fun√ß√£o de ativa√ß√£o:** Garante que os valores fiquem dentro de um intervalo (ex: `sigmoid`, que for√ßa os valores entre 0 e 1).

---

## üéØ Como a rede aprende?

O processo de **aprendizado (learning)** √© encontrar a **quantidade certa de ativa√ß√£o** entre os neur√¥nios.
 Isso √© feito atrav√©s de algoritmos como:

- **Propaga√ß√£o para frente (forward propagation)**:  
  Os dados passam camada por camada at√© a sa√≠da.

- **C√°lculo do erro**:  
  A sa√≠da gerada √© comparada com a sa√≠da correta (esperada).

- **Retropropaga√ß√£o (backpropagation)**:  
  O erro √© distribu√≠do para os neur√¥nios anteriores e os **pesos s√£o ajustados** com base nesse erro.

---

## üß© Exemplo de Aplica√ß√£o

Imagine uma rede neural que reconhece **n√∫meros manuscritos** com base em **pixels** de uma imagem:

- Os **neur√¥nios da entrada** recebem os pixels.
- As **camadas ocultas** detectam padr√µes como linhas, curvas, cantos.
- A **√∫ltima camada** determina **qual n√∫mero est√° na tela**.

Para refor√ßar o aprendizado:
- A rede aplica **pesos positivos** para padr√µes desejados.
- Aplica **pesos negativos** ao que est√° fora do padr√£o.
- A **fun√ß√£o sigmoid** garante que as ativa√ß√µes fiquem entre 0 e 1.

---
