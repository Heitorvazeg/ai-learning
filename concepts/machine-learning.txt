# üìö Machine Learning: Fundamentos e Conceitos

Machine Learning (ML) √© um campo da Intelig√™ncia Artificial (IA) que permite que m√°quinas **aprendam a partir de dados**
 sem serem explicitamente programadas para cada tarefa.

Em vez de escrever passo a passo o que deve ser feito, voc√™ **fornece exemplos**, e o modelo **aprende sozinho a identificar padr√µes**.

---

## üß† Como funciona?

1. **Coleta de dados**
2. **Treina o modelo com os dados**
3. **Testa com novos dados**

---

## üß™ Tipos de Aprendizado

### üî∑ Supervisionado

Voc√™ fornece **dados com r√≥tulos (labels)**. O modelo aprende a prever os r√≥tulos com base nas entradas.

#### üî∏ Tarefas comuns:

- **Classifica√ß√£o**: prever classes discretas.
  - Ex: Gato vs. Cachorro, Tipos de frutas
  - Pode ser **bin√°ria** (2 classes) ou **multiclasse**
  
- **Regress√£o**: prever valores cont√≠nuos (n√∫meros reais).
  - Ex: Temperatura, Pre√ßo de uma casa

---

### üî∑ N√£o Supervisionado

Voc√™ fornece **dados sem r√≥tulos**, e o modelo tenta **descobrir padr√µes ou agrupamentos** por conta pr√≥pria.
Unsupervised Clustering -> Assume grupos ao mundo.
A representa√ß√£o do mundo pode ser a fun√ß√£o.
Com imagens: Representation learning.

Mais complexo; analisa em tempo real; precis√£o moderada.
Anomaly Detection: Acha casos que fogem muito aos grupos padr√µes.

Partitional Clustering: Divide os dados em conjuntos que n√£o se sobrepoem. Parti√ß√µes.
  - R√°pido.
  - F√°cil de interpretar.
  - Precisa definir K antes.
  - Sem hierarquia
  - Busca minimizar alguma fun√ß√£o de custo, geralmente relacionada √† dist√¢ncia dos pontos
  aos centro do cluster.

  Algoritmos:
  K-means -> Escolhe K, o n√∫mero de clusters. Inicia K centr√≥ides (N√∫meros que representam
  cada cluster). atribui√ß√£o de pontos aos clusters cujo centr√≥ide est√° mais pr√≥ximo. Recalcula
  os centr√≥ides com a m√©dia de todos os pontos. Repete.
  - Os centr√≥ides podem ser alguns pr√≥prios pontos. Ponto m√©dio de um cluster. N√£o √© necessariamente
  um ponto do cluster.

Hierarchical Clustering: Uma √°rvore que tem um conjunto de agrupamentos.
  - √â necess√°rio calcular a dist√¢ncia entre clusters para encontrar os mais proximos e agrup√°-los.
  - Utiliza-se uma matriz de dist√¢ncias.
  - A dist√¢ncia entre pontos pode ser Euclidiana, manhattan...
  - Dist√¢ncia entre Clusters: Como vai ser medida a dist√£ncia...
  Single linkage - Dist√¢ncia minima entre dois pontos dos clusters. Complete linkage - Dist√¢n-
  cia m√°xima. Average linkage - Distancia m√©dia entre todos os pontos...

  - O(n^3) - Custoso.
  - N√£o precisa definir o n√∫mero de clusters inicialmente.

  Aglomerativo: Mais comum. Come√ßa cada um sendo seu proprio conjunto. Os agrupamentos
  mais proximos s√£o fundidos. √Årvore chamada de dendrograma. Abordagem bottom-up.

  Divisivo: Todos os pontos come√ßam em um √∫nico agrupamento e s√£o divididos. Menos usado
  por ser mais custoso.
---

### üî∑ Aprendizado por Refor√ßo

O modelo aprende com **tentativa e erro**, recebendo **recompensas** ou **penalidades** com base nas decis√µes que toma.

---

## ‚öôÔ∏è O que √© um Modelo?

Um **modelo** √© uma fun√ß√£o que:

- Recebe entradas (features)
- Processa essas entradas
- Retorna uma sa√≠da (previs√£o)

Durante o **aprendizado**, o modelo:

1. Recebe dados de entrada
2. Faz uma previs√£o
3. Compara com o valor real
4. Ajusta seus par√¢metros para melhorar com base na **fun√ß√£o de perda (loss)**

---

## ‚ùå Fun√ß√µes de Perda (Loss Functions)

A fun√ß√£o de perda mede o **erro da previs√£o** comparado ao valor verdadeiro.

- **L1 Loss (Erro Absoluto M√©dio)**:
Loss = sum(| y_real - y_previsto |)

- **L2 Loss (Erro Quadr√°tico M√©dio)**:
Loss = sum(( y_real - y_previsto )¬≤)
---

## ‚úÖ M√©tricas

- **Accuracy (Precis√£o)**: porcentagem de previs√µes corretas (muito usada em classifica√ß√£o)

---

## üîÅ Divis√£o dos Dados

- **Treinamento**: usado para ajustar o modelo (tem feedback do loss)
- **Valida√ß√£o**: avalia o modelo em dados **nunca vistos** durante o treino (sem feedback)
- **Teste**: avalia√ß√£o final, simula o uso real do modelo com dados totalmente novos

---

## üßæ Tipos de Dados (Features)

### üìä Qualitativos (Categ√≥ricos)

- Representam **categorias** distintas
- Ex: G√™nero, Nacionalidade

#### ‚û§ One-hot Encoding:
Transforma categorias em vetores num√©ricos:
```text
Ex: G√™nero (Masculino, Feminino)
‚Üí [1, 0] ou [0, 1]
Nominais: sem ordem natural entre os valores (ex: cor dos olhos)

Ordinais: com ordem natural (ex: beb√™ < jovem < adulto)

üî¢ Quantitativos (Num√©ricos)
Valores que representam quantidades

Podem ser:

-Discretos: n√∫mero de filhos, andares
-Cont√≠nuos: temperatura, altura, dist√¢ncia